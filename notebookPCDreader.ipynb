{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps\n",
    "\n",
    "~~target point cloud made from CAD file~~\n",
    "\n",
    "fix filter/output on RANSAC \n",
    "+ ~~disable mutual filtering~~\n",
    "+ change feature extraction params\n",
    "+ less downsampling (can try to greater extent)\n",
    "+ change feature types (SHOT or within FPFH)\n",
    "+ change dist threshold\n",
    "+ try fast global registration?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "PointCloud with 13939 points.\n",
      "[[-0.275 -0.213 -2.349]\n",
      " [-0.241 -0.213 -2.347]\n",
      " [-0.174 -0.213 -2.346]\n",
      " ...\n",
      " [-0.8   -0.81  -2.306]\n",
      " [-0.75  -0.801 -2.309]\n",
      " [-0.704 -0.797 -2.322]]\n"
     ]
    }
   ],
   "source": [
    "# READ DATA FILE\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(\"JUST-TM-62.pcd\")\n",
    "print(pcd)\n",
    "print(np.asarray(pcd.points))\n",
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALTERNATIVELY (PREFERRED) USE TM62 CAD FILE AS TARGET\n",
    "\n",
    "mesh = o3d.io.read_triangle_mesh(\"Hollow_62_Clinic.stl\")\n",
    "point_cloud = mesh.sample_points_uniformly(number_of_points=100) # very sparse sampling, default is 100x higher\n",
    "o3d.io.write_point_cloud(\"TM62_target.pcd\", point_cloud)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore this for now\n",
    "\n",
    "def radius_search():\n",
    "    print(\"Loading pointcloud ...\")\n",
    "    sample_pcd_data = o3d.data.PCDPointCloud()\n",
    "    # pcd = o3d.io.read_point_cloud(\"p213.pcd\")\n",
    "    pcd = o3d.io.read_point_cloud(\"JUST-TM-62.pcd\")\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "    print(\n",
    "        \"Find the neighbors of 50000th point with distance less than 0.2, and painting them green ...\"\n",
    "    )\n",
    "    [k, idx, _] = pcd_tree.search_radius_vector_3d(pcd.points[50000], 0.2)\n",
    "    np.asarray(pcd.colors)[idx[1:], :] = [0, 1, 0]\n",
    "\n",
    "    print(\"Displaying the final point cloud ...\\n\")\n",
    "    o3d.visualization.draw([pcd])\n",
    "\n",
    "def knn_search():\n",
    "    print(\"Loading pointcloud ...\")\n",
    "    sample_pcd = o3d.data.PCDPointCloud()\n",
    "    pcd = o3d.io.read_point_cloud(sample_pcd.path)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "    print(\n",
    "        \"Find the 2000 nearest neighbors of 50000th point, and painting them red ...\"\n",
    "    )\n",
    "    [k, idx, _] = pcd_tree.search_knn_vector_3d(pcd.points[50000], 2000)\n",
    "    np.asarray(pcd.colors)[idx[1:], :] = [1, 0, 0]\n",
    "\n",
    "    print(\"Displaying the final point cloud ...\\n\")\n",
    "    o3d.visualization.draw([pcd])\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     knn_search()\n",
    "#     radius_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# Load point clouds\n",
    "source = o3d.io.read_point_cloud(\"pointCloud1.pcd\", format='pcd')\n",
    "target = o3d.io.read_point_cloud(\"TM62_target.pcd\", format='pcd')\n",
    "\n",
    "# want to scale down target\n",
    "# Define the scaling factor (e.g., 0.5 to reduce size by half)\n",
    "scaling_factor = 0.05\n",
    "\n",
    "# Extract point coordinates\n",
    "points = np.asarray(target.points)\n",
    "\n",
    "# Apply scaling\n",
    "scaled_points = points * scaling_factor\n",
    "\n",
    "# Create a new point cloud with scaled points\n",
    "scaled_pcd = o3d.geometry.PointCloud()\n",
    "scaled_pcd.points = o3d.utility.Vector3dVector(scaled_points)\n",
    "\n",
    "target = scaled_pcd\n",
    "\n",
    "# Downsample and estimate normals\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "    return pcd_down\n",
    "\n",
    "def preprocess_point_cloud_wout_downsample(pcd, voxel_size):\n",
    "    # pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "    pcd_down = pcd\n",
    "    return pcd_down\n",
    "\n",
    "voxel_size = 0.05\n",
    "source_down = preprocess_point_cloud(source, voxel_size) # TRY SKIPPING DOWNSAMPLING OF FIELD\n",
    "target_down = preprocess_point_cloud(target, voxel_size)\n",
    "\n",
    "# Apply manual scaling if needed\n",
    "scale_factor = 1.0  # Adjust this value as needed\n",
    "source_scaled = o3d.geometry.PointCloud()\n",
    "source_scaled.points = o3d.utility.Vector3dVector(np.array(source_down.points) * scale_factor)\n",
    "source_scaled.normals = source_down.normals  # Preserve normals\n",
    "\n",
    "\n",
    "\n",
    "# # CROP TARGET POINT CLOUD TO JUST LANDMINE (not needed w/ CAD)\n",
    "\n",
    "# # Define bounding box\n",
    "# min_bound = np.array([-3, -3, -3])  # Z, X/Y\n",
    "# max_bound = np.array([0, 0, -1])     \n",
    "\n",
    "# # Create AxisAlignedBoundingBox\n",
    "# box = o3d.geometry.AxisAlignedBoundingBox(min_bound=min_bound, max_bound=max_bound)\n",
    "\n",
    "# # Crop point cloud\n",
    "# cropped_target_pcd = target_down.crop(box)\n",
    "\n",
    "\n",
    "\n",
    "# target_down = cropped_target_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#o3d.visualization.draw_geometries([source_down])\n",
    "\n",
    "o3d.visualization.draw_geometries([target_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPFH \n",
    "\n",
    "# Compute FPFH features\n",
    "def compute_fpfh_features(pcd, voxel_size):\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*100, max_nn=500))\n",
    "    return fpfh\n",
    "\n",
    "source_fpfh = compute_fpfh_features(source_scaled, voxel_size)\n",
    "target_fpfh = compute_fpfh_features(target_down, voxel_size)\n",
    "\n",
    "# source_fpfh\n",
    "# target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RANSAC\n",
    "\n",
    "# RANSAC based alignment\n",
    "distance_threshold = voxel_size * 10\n",
    "mutual_filter = False\n",
    "result_ransac = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_scaled, target_down, source_fpfh, target_fpfh, mutual_filter, distance_threshold,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "    4, [\n",
    "        o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "        o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    ],\n",
    "    o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 0.999)\n",
    ")\n",
    "\n",
    "print(result_ransac.transformation)\n",
    "\n",
    "# # Refine the alignment using ICP\n",
    "# result_icp = o3d.pipelines.registration.registration_icp(\n",
    "#     source_scaled, target_down, distance_threshold, result_ransac.transformation,\n",
    "#     o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "# )\n",
    "\n",
    "# print(result_icp.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE RESULTS\n",
    "\n",
    "# Apply the RANSAC transformation to the source point cloud\n",
    "source_transformed = source_scaled.transform(result_ransac.transformation)\n",
    "\n",
    "# Assign different colors to the point clouds for better visualization\n",
    "source_transformed.paint_uniform_color([1.0, 0.0, 0.0])  # Red\n",
    "target_down.paint_uniform_color([0.0, 1.0, 0.0])  # Green\n",
    "\n",
    "# Visualize the transformed source and target point clouds\n",
    "o3d.visualization.draw_geometries([source_transformed, target_down],\n",
    "                                   window_name=\"Transformed Source and Target Point Clouds\",\n",
    "                                   width=800, height=600)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
